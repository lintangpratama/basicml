{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "JWXONJsaVrgO",
    "outputId": "b2779160-4162-4754-92bb-08e6c57111e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anscombe.json', 'README.md', 'california_housing_test.csv', 'mnist_test.csv', 'california_housing_train.csv', 'mnist_train_small.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  ...  median_income  median_house_value\n",
       "0    -114.31     34.19  ...         1.4936             66900.0\n",
       "1    -114.47     34.40  ...         1.8200             80100.0\n",
       "2    -114.56     33.69  ...         1.6509             85700.0\n",
       "3    -114.57     33.64  ...         3.1917             73400.0\n",
       "4    -114.57     33.57  ...         1.9250             65500.0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO DATAFRAMES\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Checking file list in 'sample_data', this file is data example from Google Colab\n",
    "print(os.listdir('sample_data'))\n",
    "\n",
    "# Read csv file\n",
    "data_train = pd.read_csv('sample_data/california_housing_train.csv') \n",
    "# Display top 5 row data\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcIeoGTwWy3_",
    "outputId": "aa0f8c2a-a117-4fe2-eaad-e541d3c868e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25806452, 0.45454545],\n",
       "       [1.        , 1.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.08064516, 0.13636364],\n",
       "       [0.16129032, 0.27272727]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NORMALIZATION (Transforming a whole data to 0-1 range)\n",
    "# Imoporting the module\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n",
    "\n",
    "# Make an MinMaxScaler object as scaler\n",
    "scaler = MinMaxScaler()\n",
    "# Fitting data to 0-1 range\n",
    "scaler.fit(data)\n",
    "# Transform data to 0-1 range\n",
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFNlfYMDYM6r",
    "outputId": "4f78d897-ffb3-4ff1-f7a7-cfa93a89cdba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11638732,  0.23521877],\n",
       "       [ 1.94277296,  1.80334389],\n",
       "       [-0.83261698, -1.07155217],\n",
       "       [-0.60879521, -0.67952089],\n",
       "       [-0.38497344, -0.28748961]])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STANDARDIZATION\n",
    "# This data preparation is using the Z score that equal to (value - mean)/standard deviation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(data)\n",
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzQgwQGnb1EH",
    "outputId": "e508149d-14ee-4b4d-af25-a2384341e322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 17, 15, 1, 8, 5]\n",
      "[0, 17, 15, 1, 8, 5]\n",
      "[0, 17, 15, 1, 8, 5]\n",
      "[0, 17, 15, 1, 8, 5]\n",
      "\n",
      "[5, 3, 1, 9, 4, 14]\n",
      "[10, 2, 6, 11, 19, 13]\n",
      "[8, 0, 9, 15, 10, 18]\n",
      "[13, 8, 1, 12, 9, 18]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train set and test set\n",
    "# Import the module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the dataset\n",
    "data_X = range(20)\n",
    "data_y = range(20)\n",
    "\n",
    "# Splitting the dataset with random state\n",
    "for i in range(4):    \n",
    "  X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=42)\n",
    "  print(y_test)\n",
    "print()\n",
    "# Splitting the dataset without random state\n",
    "for i in range(4):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=None)\n",
    "  print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lt3479x_f5I_",
    "outputId": "157d71f5-9237-45a8-8a6b-261bf279e70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.8 4.7 1.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [4.8 3.1 1.6 0.2]] [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Train test split using iris dataset from SKLearn\n",
    "# Import modul sklearn dan dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load iris dataset\n",
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "# Initialize the attributes for X and the label for y\n",
    "X = iris_dataset.data\n",
    "y = iris_dataset.target\n",
    "\n",
    "# Splitting the iris_dataset into train data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "print(X_test, y_test)\n",
    "# The output is the 20% dataset that become a test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSADIvRdsLLw",
    "outputId": "02387539-d555-47e3-eda8-b09af811b6a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA EVALUATION (CROSS VALIDATION SPLIT)\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# load iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# defining attributes and labels from dataset\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Making the decision tree classifier model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Checking the validation score\n",
    "score = cross_val_score(clf, X, y, cv=5)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
